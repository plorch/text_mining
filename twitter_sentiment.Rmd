---
title: "twitter_sentiment example"
author: "Patrick Lorch"
date: "9/27/2020"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: no
    number_sections: true
    theme: cerulean
    highlight: haddock
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Text Workshop CMP example

This is derived from 

https://github.com/oharac/text_workshop

and specifically the part called "4_sentiment_twitter_2018.*"

For this to work, you have to (see above link for details):

* get a twitter dev account and 
* record keys in safe place
* set up an app, with certain priveldges 
  * read/write
  * setlookup URL
  
## R basics

This example uses "Tidy" R functions and workflow

* More readable
* Easier to re-run
* Has SQL like functions
* Uses tibbles instead of data.frames
  * These are a pain to view
  * More strict variable typing

## Basic Twitter API query

Key points:

* defaults to `type = "recent"`
  * returns data from only last 6-9 days
* includes retweets
  * assumes retweeters share original sentiment
* `retryonratelimit = FALSE` by default
  * cuts off query at ratelimit
    * after 8-10% of full request in my case
  * set TRUE when done testing
* remove some of the columns and un-nest hashtags

```{r twitter}
library(tidyverse) # functions for working with tidy data
library(stringr) # tidy string manipulation functions

# install.packages('rtweet')
library(rtweet) # functions to interact with twitter API

# twitter keys, not uploaded with github project
# Comment if not knitting
# twitter_key <- scan('~/github/api_keys/twitter.txt', what = 'character')
# consumer_key    <- twitter_key[1]
# consumer_secret <- twitter_key[2]

# Create token and allow access by this app
# Comment if knitting
# rtweet::create_token(app = "Park Sentiment Analysis", 
#                      consumer_key, consumer_secret,
#                      set_renv = TRUE)

# If a file that is adequate is not already in memory
#  This saves you using up your free twitter queries
if(!file.exists("data/cmp_tweets_file.txt")) { 
  ### A bit slow, so save it for future use...
  
  # Let's look at the key function
  # ?rtweet::search_tweets
  
  tw_cm_raw <- rtweet::search_tweets('@clevemetroparks OR 
                                     (cleve AND metropark)', 
# Uncomment this when you are done debugging
#                                     retryonratelimit = T,
                                     n = 10000,
                                     include_rts = TRUE)
  # View(tw_cm_raw)
  # Comment if knitting
  # unique(tw_cm_raw$screen_name[order(tw_cm_raw$screen_name)])

  tw_cm <- tw_cm_raw %>%
    select(status_id, created_at, screen_name,
           text, source, 
           is_quote, is_retweet,
           hashtags, favorite_count, retweet_count,
           contains('place'),
           contains('country')) %>%
    unnest(hashtags)

  # View(tw_cm)

  write_csv(tw_cm, "data/cmp_tweets_file.txt")
  
} else {
  
  tw_cm <- read_csv("data/cmp_tweets_file.txt")
  
}

# remove keys so R does not save them in .rhistory
# Comment if knitting
# rm(consumer_key, consumer_secret, twitter_key)

```

## Clean up input data

* Remove 
  * User information
  * Tweets by CMP
  * Staff tweets and retweets still included
  * URLs
* Make a device variable for later comparisons
* Lower case of hashtags

```{r clean}
### Set up some devices and hashtags we want to test:
devices <- c('iphone', 'ipad', 'android') %>% 
  paste(collapse = '|')
# cm_hash <- c('cleve', 'metropark', 'trail')
cm_handles = c('clevemetroparks', 
               'clemetzoo', 
               'clevezoosociety')

tw_phone <- tw_cm %>%
  select(created_at, screen_name, text, source, 
         # place_full_name, country,
         hashtags) %>%
  filter(#tolower(hashtags) %in% cm_hash, 
         !tolower(screen_name) %in% cm_handles) %>%
  mutate(text = str_replace_all(text, '[^[:ascii:]]', '_') %>% 
           tolower(),
         text_clean = str_replace_all(text, '@[^ ]+', '_usr_'),
         text_clean = str_replace_all(text_clean, 'http[^ ]+', '_url_')) %>%
  mutate(device = str_match(tolower(source), devices))
  
### A couple more cleanups
tw_phone <- tw_phone %>%
  mutate(hashtags = tolower(hashtags),
         device = ifelse(is.na(device), 'other', device))
 
```


## Sentiment analysis

What are people saying?

Contrived example:
Q1: Are iPhone users more positive than android users?

This section uses `tidytext::get_sentiments` to bring in sentiment value assignment dictionaries.

We need to modify these because, for example, chagrin is not a negative word for us, it is neutral and a place, so not a sentiment word.

Key points:

* Un-nest words from cleaned text field
* Remove "stop words" (e.g., the, a, him, etc.)
* Assign sentiment to words found in sentiment dictionary

```{r sentiment}
library(tidytext)

sentiments_b <- tidytext::get_sentiments('bing')
sentiments_a <- tidytext::get_sentiments('afinn')
sentiments_n <- tidytext::get_sentiments('nrc')
# sentiments_l <- tidytext::get_sentiments('loughran')

# Fix sentiments for words that mean something different for
# parks.  This is done just by looking through words from recent
# tweets in test_df, not going through sentiments_b line by
# line.

# Requires you to generate test_df, look at words, then
# regenerate test_df

sentiments_b_parks = sentiments_b %>%
  mutate(sentiment = case_when(word == "untouched" ~ "positive",
                          word == "jealous" ~ "positive",
                          TRUE ~sentiment))

# This works too
# sentiments_b_parks = sentiments_b %>%
#   mutate(sentiment = if_else(word == "untouched" | 
#                                word == "jealous", 
#                              "positive",sentiment))

# Testing
sentiments_b[sentiments_b$word == "untouched",]
sentiments_b[sentiments_b$word == "jealous",]
sentiments_b_parks[sentiments_b_parks$word == "untouched",]
sentiments_b_parks[sentiments_b_parks$word == "jealous",]

# Remove some other words that are not negative in parks
#  For this to work you have to first set to_remove after 
#  running this once and looking at the words_n
to_remove = c("chagrin", "concession", "fall",
                   "falls", "hollow", "overlook", "retreat", 
                   "rocky", "scramble")
sentiments_b_parks = sentiments_b_parks[!sentiments_b_parks$word %in% to_remove,]

test_df <- tw_phone %>%
  tidytext::unnest_tokens(output = word, 
                          input = text_clean, 
                          token = 'words') %>%
  anti_join(tidytext::stop_words, by = 'word') %>%
  left_join(sentiments_b_parks, by = 'word')

### Check the sentiment assignments by word - 
### some are pretty funny, but also shows 
### limitation of the word bank used

(words_n = unique(test_df$word[test_df$sentiment == "negative"]))
(words_p = unique(test_df$word[test_df$sentiment == "positive"]))

score_df_raw <- test_df %>%
  count(device, hashtags, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n) %>%
  mutate(score = (positive - negative) - 
           mean(positive - negative, na.rm = TRUE))

# remove hashtags with no score (either no pos or no neg)
score_df = score_df_raw %>% 
  filter(!is.na(score))
mean(score_df$positive - score_df$negative)
  
ggplot(score_df, aes(x = device, fill = hashtags)) +
  theme_classic() +
  geom_bar(aes(y = score), stat = 'identity', position = 'dodge') +
  labs(y = 'sentiment score') +
  coord_flip()

```

